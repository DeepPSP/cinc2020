{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T14:35:16.155651Z",
     "start_time": "2020-04-23T14:35:16.126878Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/export/servers/wenhao/database_reader/\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T14:35:20.282829Z",
     "start_time": "2020-04-23T14:35:16.419128Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/python-3.6.8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import database_reader as dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T14:35:20.502918Z",
     "start_time": "2020-04-23T14:35:20.463111Z"
    }
   },
   "outputs": [],
   "source": [
    "import database_reader.utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T14:35:20.718916Z",
     "start_time": "2020-04-23T14:35:20.678380Z"
    }
   },
   "outputs": [],
   "source": [
    "from database_reader import CPSC2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T14:35:21.122247Z",
     "start_time": "2020-04-23T14:35:21.028237Z"
    }
   },
   "outputs": [],
   "source": [
    "hehe_cpsc = CPSC2018(db_path=\"/export/servers/data/CPSC2018/Training_WFDB/\", verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:58:25.553151Z",
     "start_time": "2020-04-22T05:58:25.459403Z"
    }
   },
   "outputs": [],
   "source": [
    "ro = 608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:58:32.061123Z",
     "start_time": "2020-04-22T05:58:31.730501Z"
    }
   },
   "outputs": [],
   "source": [
    "hehe_cpsc.load_ann(ro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T05:55:03.185132Z",
     "start_time": "2020-04-22T05:55:03.104012Z"
    }
   },
   "outputs": [],
   "source": [
    "hehe_cpsc.load_data(ro)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T03:48:54.374043Z",
     "start_time": "2020-04-22T03:48:54.146339Z"
    }
   },
   "outputs": [],
   "source": [
    "hehe_cpsc.load_ann(1)['df_leads']['lead_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T04:07:33.676862Z",
     "start_time": "2020-04-22T03:53:39.480598Z"
    }
   },
   "outputs": [],
   "source": [
    "for ro in range(1, hehe_cpsc.nb_records+1):\n",
    "    try:\n",
    "        ll = hehe_cpsc.load_ann(ro)['df_leads']['lead_name'].tolist()\n",
    "        if ll != ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']:\n",
    "            print(f\"第{ro}个record的导联顺序不一样\")\n",
    "    except Exception as e:\n",
    "        print(f\"第{ro}个record发生了如下错误\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T06:15:30.231170Z",
     "start_time": "2020-04-22T06:01:35.140659Z"
    }
   },
   "outputs": [],
   "source": [
    "for ro in range(1, hehe_cpsc.nb_records+1):\n",
    "    try:\n",
    "        ll = hehe_cpsc.load_data(ro)[:,0]\n",
    "        fv = hehe_cpsc.load_ann(ro)['df_leads']['first_value'].values\n",
    "        if (ll!=fv).any():\n",
    "            print(f\"第{ro}个record的导联顺序不一样\")\n",
    "    except Exception as e:\n",
    "        print(f\"第{ro}个record发生了如下错误\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T01:46:27.772229Z",
     "start_time": "2020-04-20T01:46:27.604617Z"
    }
   },
   "outputs": [],
   "source": [
    "hehe_cpsc.get_labels(ro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T01:46:28.078076Z",
     "start_time": "2020-04-20T01:46:27.910120Z"
    }
   },
   "outputs": [],
   "source": [
    "hehe_cpsc.get_diagnosis(ro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T01:46:37.415116Z",
     "start_time": "2020-04-20T01:46:37.301660Z"
    }
   },
   "outputs": [],
   "source": [
    "hehe_cpsc.load_data(ro).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T01:50:04.979149Z",
     "start_time": "2020-04-20T01:49:47.851388Z"
    }
   },
   "outputs": [],
   "source": [
    "hehe_cpsc.plot(ro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T17:29:41.984984Z",
     "start_time": "2020-04-23T17:29:41.893092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hehe_cpsc.load_data(1).shape[0]//3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T17:21:15.824083Z",
     "start_time": "2020-04-23T17:21:15.733043Z"
    }
   },
   "outputs": [],
   "source": [
    "input_len = 6*hehe_cpsc.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T17:28:22.956018Z",
     "start_time": "2020-04-23T17:28:22.859940Z"
    }
   },
   "outputs": [],
   "source": [
    "x,y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T17:53:03.794174Z",
     "start_time": "2020-04-23T17:31:18.558548Z"
    }
   },
   "outputs": [],
   "source": [
    "for ro in range(1, hehe_cpsc.nb_records+1):\n",
    "    ecg = hehe_cpsc.load_data(ro)\n",
    "    ann = hehe_cpsc.get_labels(ro)\n",
    "    for i in range(ecg.shape[0]//input_len):\n",
    "        x.append(ecg[input_len*i:input_len*(i+1)])\n",
    "        y.append(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:03:55.899869Z",
     "start_time": "2020-04-23T18:03:55.826275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((x[0]-np.mean(x[0]))/np.std(x[0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:04:28.367112Z",
     "start_time": "2020-04-23T18:04:19.543488Z"
    }
   },
   "outputs": [],
   "source": [
    "new_x = [(item-np.mean(item))/np.std(item) for item in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:08:49.445856Z",
     "start_time": "2020-04-23T18:08:45.455525Z"
    }
   },
   "outputs": [],
   "source": [
    "new_x = np.array(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:09:12.148733Z",
     "start_time": "2020-04-23T18:09:12.100071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14579, 3000, 12)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:09:35.188076Z",
     "start_time": "2020-04-23T18:09:35.139291Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:14:47.222054Z",
     "start_time": "2020-04-23T18:14:47.127527Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('./cpsc_y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:15:13.364644Z",
     "start_time": "2020-04-23T18:15:10.033774Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('./cpsc_x.npy', new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1,1,10],[2,3,50]]) - np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:31:42.062074Z",
     "start_time": "2020-04-23T18:31:41.973668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N', 'AF', 'I-AVB', 'LBBB', 'RBBB', 'PAC', 'PVC', 'STD', 'STE']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hehe_cpsc.all_diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:36:46.995762Z",
     "start_time": "2020-04-23T18:36:46.943006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y = np.zeros((new_x.shape[0],9))\n",
    "new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:39:28.255520Z",
     "start_time": "2020-04-23T18:39:28.061930Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx, item in enumerate(y):\n",
    "    indices = [hehe_cpsc.all_diagnosis.index(l) for l in item]\n",
    "    new_y[idx][indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:40:35.736302Z",
     "start_time": "2020-04-23T18:40:35.632737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]),\n",
       " ['RBBB'],\n",
       " ['N', 'AF', 'I-AVB', 'LBBB', 'RBBB', 'PAC', 'PVC', 'STD', 'STE'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y[0],y[0], hehe_cpsc.all_diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:16:56.690349Z",
     "start_time": "2020-04-23T18:16:56.586217Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x = new_x[:12000]\n",
    "test_x = new_x[12000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:17:19.827475Z",
     "start_time": "2020-04-23T18:17:19.777434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 3000, 12)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:12:57.809448Z",
     "start_time": "2020-04-29T03:12:57.705475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 9)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:41:12.491129Z",
     "start_time": "2020-04-23T18:41:12.403408Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y = new_y[:12000]\n",
    "test_y = new_y[12000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:18:36.803151Z",
     "start_time": "2020-07-24T11:18:36.692392Z"
    }
   },
   "outputs": [],
   "source": [
    "?BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:41:37.216668Z",
     "start_time": "2020-04-23T18:41:34.874515Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import (\n",
    "    LSTM, GRU,\n",
    "    TimeDistributed, Bidirectional,\n",
    "    ReLU, LeakyReLU,\n",
    "    BatchNormalization,\n",
    "    Dense, Dropout, Activation, Flatten, \n",
    "    Input, Reshape, GRU, CuDNNGRU,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    GlobalAveragePooling1D, AveragePooling1D,\n",
    "    concatenate,\n",
    ")\n",
    "from keras.initializers import he_normal, he_uniform, Orthogonal\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "freq = 500\n",
    "cell_len_t = 6\n",
    "nb_classes = 9\n",
    "batch_size=128\n",
    "\n",
    "\n",
    "TI_CNN = Sequential(name='TI_CNN')\n",
    "\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        input_shape = (freq*cell_len_t, 12),\n",
    "        filters=64, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        filters=64, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    MaxPooling1D(\n",
    "        pool_size=3, strides=3,\n",
    "    )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        filters=128, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        filters=128, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    MaxPooling1D(\n",
    "        pool_size=3, strides=3,\n",
    "    )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        filters=256, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        filters=256, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        filters=256, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    MaxPooling1D(\n",
    "        pool_size=3, strides=3,\n",
    "    )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        filters=512, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        filters=512, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        filters=512, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    MaxPooling1D(\n",
    "        pool_size=3, strides=3,\n",
    "    )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        filters=512, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        filters=512, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    Conv1D(\n",
    "        filters=512, kernel_size=3, strides=1, padding='same',\n",
    "        kernel_initializer=he_normal(SEED),\n",
    "        )\n",
    ")\n",
    "TI_CNN.add(\n",
    "    BatchNormalization()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    ReLU()\n",
    ")\n",
    "TI_CNN.add(\n",
    "    MaxPooling1D(\n",
    "        pool_size=3, strides=3,\n",
    "    )\n",
    ")\n",
    "\n",
    "TI_CNN.add(\n",
    "    LSTM(\n",
    "        128, kernel_initializer=Orthogonal(seed=SEED),\n",
    "        return_sequences=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "TI_CNN.add(\n",
    "    LSTM(\n",
    "        32, kernel_initializer=Orthogonal(seed=SEED),\n",
    "        return_sequences=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "TI_CNN.add(\n",
    "    LSTM(\n",
    "        9, kernel_initializer=Orthogonal(seed=SEED),\n",
    "        return_sequences=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "TI_CNN.add(\n",
    "    Dense(nb_classes,activation='sigmoid')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-23T18:41:18.555Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TI_CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 3000, 64)          2368      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 3000, 64)          256       \n",
      "_________________________________________________________________\n",
      "re_lu_27 (ReLU)              (None, 3000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 3000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 3000, 64)          256       \n",
      "_________________________________________________________________\n",
      "re_lu_28 (ReLU)              (None, 3000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 1000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_29 (ReLU)              (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_30 (ReLU)              (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 333, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 333, 256)          98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 333, 256)          1024      \n",
      "_________________________________________________________________\n",
      "re_lu_31 (ReLU)              (None, 333, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 333, 256)          196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 333, 256)          1024      \n",
      "_________________________________________________________________\n",
      "re_lu_32 (ReLU)              (None, 333, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 333, 256)          196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 333, 256)          1024      \n",
      "_________________________________________________________________\n",
      "re_lu_33 (ReLU)              (None, 333, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 111, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 111, 512)          393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 111, 512)          2048      \n",
      "_________________________________________________________________\n",
      "re_lu_34 (ReLU)              (None, 111, 512)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 111, 512)          786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 111, 512)          2048      \n",
      "_________________________________________________________________\n",
      "re_lu_35 (ReLU)              (None, 111, 512)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 111, 512)          786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 111, 512)          2048      \n",
      "_________________________________________________________________\n",
      "re_lu_36 (ReLU)              (None, 111, 512)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 37, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 37, 512)           786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 37, 512)           2048      \n",
      "_________________________________________________________________\n",
      "re_lu_37 (ReLU)              (None, 37, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 37, 512)           786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 37, 512)           2048      \n",
      "_________________________________________________________________\n",
      "re_lu_38 (ReLU)              (None, 37, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 37, 512)           786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 37, 512)           2048      \n",
      "_________________________________________________________________\n",
      "re_lu_39 (ReLU)              (None, 37, 512)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 12, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 12, 128)           328192    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 12, 32)            20608     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 9)                 1512      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 90        \n",
      "=================================================================\n",
      "Total params: 5,276,738\n",
      "Trainable params: 5,268,290\n",
      "Non-trainable params: 8,448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "TI_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-23T18:41:20.373Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "TI_CNN.compile(loss='binary_crossentropy', optimizer=Adam(0.0001))\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', verbose=1, monitor='val_acc', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-23T18:41:21.848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/python-3.6.8/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 12000 samples, validate on 2579 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 310s 26ms/step - loss: 0.5346 - val_loss: 0.4976\n",
      "\n",
      "Epoch 00001: saving model to /tmp/weights.hdf5\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 205s 17ms/step - loss: 0.4627 - val_loss: 0.4511\n",
      "\n",
      "Epoch 00002: saving model to /tmp/weights.hdf5\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 203s 17ms/step - loss: 0.4287 - val_loss: 0.4281\n",
      "\n",
      "Epoch 00003: saving model to /tmp/weights.hdf5\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 206s 17ms/step - loss: 0.4039 - val_loss: 0.4149\n",
      "\n",
      "Epoch 00004: saving model to /tmp/weights.hdf5\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 208s 17ms/step - loss: 0.3851 - val_loss: 0.3939\n",
      "\n",
      "Epoch 00005: saving model to /tmp/weights.hdf5\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 205s 17ms/step - loss: 0.3688 - val_loss: 0.3813\n",
      "\n",
      "Epoch 00006: saving model to /tmp/weights.hdf5\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 212s 18ms/step - loss: 0.3553 - val_loss: 0.3766\n",
      "\n",
      "Epoch 00007: saving model to /tmp/weights.hdf5\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 209s 17ms/step - loss: 0.3440 - val_loss: 0.3696\n",
      "\n",
      "Epoch 00008: saving model to /tmp/weights.hdf5\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 217s 18ms/step - loss: 0.3346 - val_loss: 0.3558\n",
      "\n",
      "Epoch 00009: saving model to /tmp/weights.hdf5\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 214s 18ms/step - loss: 0.3248 - val_loss: 0.3503\n",
      "\n",
      "Epoch 00010: saving model to /tmp/weights.hdf5\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 212s 18ms/step - loss: 0.3167 - val_loss: 0.3409\n",
      "\n",
      "Epoch 00011: saving model to /tmp/weights.hdf5\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 215s 18ms/step - loss: 0.3089 - val_loss: 0.3431\n",
      "\n",
      "Epoch 00012: saving model to /tmp/weights.hdf5\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 218s 18ms/step - loss: 0.3017 - val_loss: 0.3460\n",
      "\n",
      "Epoch 00013: saving model to /tmp/weights.hdf5\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 213s 18ms/step - loss: 0.2960 - val_loss: 0.3265\n",
      "\n",
      "Epoch 00014: saving model to /tmp/weights.hdf5\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 216s 18ms/step - loss: 0.2905 - val_loss: 0.3275\n",
      "\n",
      "Epoch 00015: saving model to /tmp/weights.hdf5\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 224s 19ms/step - loss: 0.2837 - val_loss: 0.3185\n",
      "\n",
      "Epoch 00016: saving model to /tmp/weights.hdf5\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 217s 18ms/step - loss: 0.2768 - val_loss: 0.3115\n",
      "\n",
      "Epoch 00017: saving model to /tmp/weights.hdf5\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 229s 19ms/step - loss: 0.2713 - val_loss: 0.3127\n",
      "\n",
      "Epoch 00018: saving model to /tmp/weights.hdf5\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 254s 21ms/step - loss: 0.2668 - val_loss: 0.3100\n",
      "\n",
      "Epoch 00019: saving model to /tmp/weights.hdf5\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 246s 21ms/step - loss: 0.2633 - val_loss: 0.3039\n",
      "\n",
      "Epoch 00020: saving model to /tmp/weights.hdf5\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 246s 21ms/step - loss: 0.2575 - val_loss: 0.2950\n",
      "\n",
      "Epoch 00021: saving model to /tmp/weights.hdf5\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 247s 21ms/step - loss: 0.2513 - val_loss: 0.2901\n",
      "\n",
      "Epoch 00022: saving model to /tmp/weights.hdf5\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 259s 22ms/step - loss: 0.2463 - val_loss: 0.2896\n",
      "\n",
      "Epoch 00023: saving model to /tmp/weights.hdf5\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 267s 22ms/step - loss: 0.2428 - val_loss: 0.2868\n",
      "\n",
      "Epoch 00024: saving model to /tmp/weights.hdf5\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 253s 21ms/step - loss: 0.2386 - val_loss: 0.2815\n",
      "\n",
      "Epoch 00025: saving model to /tmp/weights.hdf5\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 249s 21ms/step - loss: 0.2345 - val_loss: 0.2860\n",
      "\n",
      "Epoch 00026: saving model to /tmp/weights.hdf5\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 273s 23ms/step - loss: 0.2312 - val_loss: 0.2790\n",
      "\n",
      "Epoch 00027: saving model to /tmp/weights.hdf5\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 283s 24ms/step - loss: 0.2269 - val_loss: 0.2825\n",
      "\n",
      "Epoch 00028: saving model to /tmp/weights.hdf5\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 279s 23ms/step - loss: 0.2235 - val_loss: 0.2756\n",
      "\n",
      "Epoch 00029: saving model to /tmp/weights.hdf5\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 261s 22ms/step - loss: 0.2202 - val_loss: 0.2785\n",
      "\n",
      "Epoch 00030: saving model to /tmp/weights.hdf5\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 254s 21ms/step - loss: 0.2197 - val_loss: 0.2737\n",
      "\n",
      "Epoch 00031: saving model to /tmp/weights.hdf5\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 250s 21ms/step - loss: 0.2157 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00032: saving model to /tmp/weights.hdf5\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 252s 21ms/step - loss: 0.2129 - val_loss: 0.2733\n",
      "\n",
      "Epoch 00033: saving model to /tmp/weights.hdf5\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 248s 21ms/step - loss: 0.2088 - val_loss: 0.2735\n",
      "\n",
      "Epoch 00034: saving model to /tmp/weights.hdf5\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 251s 21ms/step - loss: 0.2061 - val_loss: 0.2680\n",
      "\n",
      "Epoch 00035: saving model to /tmp/weights.hdf5\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 251s 21ms/step - loss: 0.2020 - val_loss: 0.2588\n",
      "\n",
      "Epoch 00036: saving model to /tmp/weights.hdf5\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 252s 21ms/step - loss: 0.1982 - val_loss: 0.2553\n",
      "\n",
      "Epoch 00037: saving model to /tmp/weights.hdf5\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 248s 21ms/step - loss: 0.1953 - val_loss: 0.2563\n",
      "\n",
      "Epoch 00038: saving model to /tmp/weights.hdf5\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 249s 21ms/step - loss: 0.1956 - val_loss: 0.2609\n",
      "\n",
      "Epoch 00039: saving model to /tmp/weights.hdf5\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 248s 21ms/step - loss: 0.1955 - val_loss: 0.2626\n",
      "\n",
      "Epoch 00040: saving model to /tmp/weights.hdf5\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 244s 20ms/step - loss: 0.1927 - val_loss: 0.2701\n",
      "\n",
      "Epoch 00041: saving model to /tmp/weights.hdf5\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 246s 20ms/step - loss: 0.1897 - val_loss: 0.2625\n",
      "\n",
      "Epoch 00042: saving model to /tmp/weights.hdf5\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 248s 21ms/step - loss: 0.1874 - val_loss: 0.2559\n",
      "\n",
      "Epoch 00043: saving model to /tmp/weights.hdf5\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 252s 21ms/step - loss: 0.1835 - val_loss: 0.2559\n",
      "\n",
      "Epoch 00044: saving model to /tmp/weights.hdf5\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 252s 21ms/step - loss: 0.1813 - val_loss: 0.2590\n",
      "\n",
      "Epoch 00045: saving model to /tmp/weights.hdf5\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 251s 21ms/step - loss: 0.1778 - val_loss: 0.2469\n",
      "\n",
      "Epoch 00046: saving model to /tmp/weights.hdf5\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 252s 21ms/step - loss: 0.1758 - val_loss: 0.2571\n",
      "\n",
      "Epoch 00047: saving model to /tmp/weights.hdf5\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 249s 21ms/step - loss: 0.1746 - val_loss: 0.2509\n",
      "\n",
      "Epoch 00048: saving model to /tmp/weights.hdf5\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 252s 21ms/step - loss: 0.1718 - val_loss: 0.2479\n",
      "\n",
      "Epoch 00049: saving model to /tmp/weights.hdf5\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 254s 21ms/step - loss: 0.1697 - val_loss: 0.2583\n",
      "\n",
      "Epoch 00050: saving model to /tmp/weights.hdf5\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 237s 20ms/step - loss: 0.1674 - val_loss: 0.2415\n",
      "\n",
      "Epoch 00051: saving model to /tmp/weights.hdf5\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 217s 18ms/step - loss: 0.1633 - val_loss: 0.2480\n",
      "\n",
      "Epoch 00052: saving model to /tmp/weights.hdf5\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 204s 17ms/step - loss: 0.1607 - val_loss: 0.2374\n",
      "\n",
      "Epoch 00053: saving model to /tmp/weights.hdf5\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 221s 18ms/step - loss: 0.1579 - val_loss: 0.2465\n",
      "\n",
      "Epoch 00054: saving model to /tmp/weights.hdf5\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 246s 20ms/step - loss: 0.1577 - val_loss: 0.2672\n",
      "\n",
      "Epoch 00055: saving model to /tmp/weights.hdf5\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 256s 21ms/step - loss: 0.1609 - val_loss: 0.2696\n",
      "\n",
      "Epoch 00056: saving model to /tmp/weights.hdf5\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 258s 21ms/step - loss: 0.1573 - val_loss: 0.2420\n",
      "\n",
      "Epoch 00057: saving model to /tmp/weights.hdf5\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 256s 21ms/step - loss: 0.1534 - val_loss: 0.2494\n",
      "\n",
      "Epoch 00058: saving model to /tmp/weights.hdf5\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 256s 21ms/step - loss: 0.1500 - val_loss: 0.2394\n",
      "\n",
      "Epoch 00059: saving model to /tmp/weights.hdf5\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 254s 21ms/step - loss: 0.1453 - val_loss: 0.2368\n",
      "\n",
      "Epoch 00060: saving model to /tmp/weights.hdf5\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 255s 21ms/step - loss: 0.1419 - val_loss: 0.2299\n",
      "\n",
      "Epoch 00061: saving model to /tmp/weights.hdf5\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 255s 21ms/step - loss: 0.1393 - val_loss: 0.2301\n",
      "\n",
      "Epoch 00062: saving model to /tmp/weights.hdf5\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 257s 21ms/step - loss: 0.1367 - val_loss: 0.2275\n",
      "\n",
      "Epoch 00063: saving model to /tmp/weights.hdf5\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 257s 21ms/step - loss: 0.1344 - val_loss: 0.2316\n",
      "\n",
      "Epoch 00064: saving model to /tmp/weights.hdf5\n",
      "Epoch 65/200\n",
      "12000/12000 [==============================] - 256s 21ms/step - loss: 0.1325 - val_loss: 0.2298\n",
      "\n",
      "Epoch 00065: saving model to /tmp/weights.hdf5\n",
      "Epoch 66/200\n",
      "12000/12000 [==============================] - 257s 21ms/step - loss: 0.1325 - val_loss: 0.2435\n",
      "\n",
      "Epoch 00066: saving model to /tmp/weights.hdf5\n",
      "Epoch 67/200\n",
      "12000/12000 [==============================] - 258s 21ms/step - loss: 0.1363 - val_loss: 0.2517\n",
      "\n",
      "Epoch 00067: saving model to /tmp/weights.hdf5\n",
      "Epoch 68/200\n",
      "12000/12000 [==============================] - 258s 21ms/step - loss: 0.1335 - val_loss: 0.2388\n",
      "\n",
      "Epoch 00068: saving model to /tmp/weights.hdf5\n",
      "Epoch 69/200\n",
      "12000/12000 [==============================] - 258s 21ms/step - loss: 0.1314 - val_loss: 0.2512\n",
      "\n",
      "Epoch 00069: saving model to /tmp/weights.hdf5\n",
      "Epoch 70/200\n",
      "12000/12000 [==============================] - 258s 21ms/step - loss: 0.1266 - val_loss: 0.2313\n",
      "\n",
      "Epoch 00070: saving model to /tmp/weights.hdf5\n",
      "Epoch 71/200\n",
      "12000/12000 [==============================] - 258s 21ms/step - loss: 0.1238 - val_loss: 0.2300\n",
      "\n",
      "Epoch 00071: saving model to /tmp/weights.hdf5\n",
      "Epoch 72/200\n",
      "12000/12000 [==============================] - 259s 22ms/step - loss: 0.1221 - val_loss: 0.2338\n",
      "\n",
      "Epoch 00072: saving model to /tmp/weights.hdf5\n",
      "Epoch 73/200\n",
      "12000/12000 [==============================] - 257s 21ms/step - loss: 0.1203 - val_loss: 0.2559\n",
      "\n",
      "Epoch 00073: saving model to /tmp/weights.hdf5\n",
      "Epoch 74/200\n",
      "12000/12000 [==============================] - 257s 21ms/step - loss: 0.1189 - val_loss: 0.2312\n",
      "\n",
      "Epoch 00074: saving model to /tmp/weights.hdf5\n",
      "Epoch 75/200\n",
      "12000/12000 [==============================] - 259s 22ms/step - loss: 0.1175 - val_loss: 0.2284\n",
      "\n",
      "Epoch 00075: saving model to /tmp/weights.hdf5\n",
      "Epoch 76/200\n",
      " 4224/12000 [=========>....................] - ETA: 2:38 - loss: 0.1167"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "TI_CNN.fit(train_x, train_y, batch_size=128, epochs=200, verbose=1, validation_data=(test_x, test_y), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:21:25.490743Z",
     "start_time": "2020-04-29T03:21:09.313128Z"
    }
   },
   "outputs": [],
   "source": [
    "submitted_model = load_model(\"./tmp/weights-0.22loss.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:22:21.739161Z",
     "start_time": "2020-04-29T03:22:01.924959Z"
    }
   },
   "outputs": [],
   "source": [
    "latest_model = load_model(\"./tmp/weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:37:15.872053Z",
     "start_time": "2020-04-29T03:37:15.753926Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_beta_score(labels, output, beta, num_classes, check_errors=True):\n",
    "\n",
    "    # Check inputs for errors.\n",
    "    if check_errors:\n",
    "        if len(output) != len(labels):\n",
    "            raise Exception('Numbers of outputs and labels must be the same.')\n",
    "\n",
    "    # Populate contingency table.\n",
    "    num_recordings = len(labels)\n",
    "\n",
    "    fbeta_l = np.zeros(num_classes)\n",
    "    gbeta_l = np.zeros(num_classes)\n",
    "    fmeasure_l = np.zeros(num_classes)\n",
    "    accuracy_l = np.zeros(num_classes)\n",
    "\n",
    "    f_beta = 0\n",
    "    g_beta = 0\n",
    "    f_measure = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    # Weight function\n",
    "    C_l=np.ones(num_classes);\n",
    "\n",
    "    for j in range(num_classes):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tn = 0\n",
    "\n",
    "        for i in range(num_recordings):\n",
    "            \n",
    "            num_labels = np.sum(labels[i])\n",
    "        \n",
    "            if labels[i][j] and output[i][j]:\n",
    "                tp += 1/num_labels\n",
    "            elif not labels[i][j] and output[i][j]:\n",
    "                fp += 1/num_labels\n",
    "            elif labels[i][j] and not output[i][j]:\n",
    "                fn += 1/num_labels\n",
    "            elif not labels[i][j] and not output[i][j]:\n",
    "                tn += 1/num_labels\n",
    "\n",
    "        # Summarize contingency table.\n",
    "        if ((1+beta**2)*tp + (fn*beta**2) + fp):\n",
    "            fbeta_l[j] = float((1+beta**2)* tp) / float(((1+beta**2)*tp) + (fn*beta**2) + fp)\n",
    "        else:\n",
    "            fbeta_l[j] = 1.0\n",
    "\n",
    "        if (tp + fp + beta * fn):\n",
    "            gbeta_l[j] = float(tp) / float(tp + fp + beta*fn)\n",
    "        else:\n",
    "            gbeta_l[j] = 1.0\n",
    "\n",
    "        if tp + fp + fn + tn:\n",
    "            accuracy_l[j] = float(tp + tn) / float(tp + fp + fn + tn)\n",
    "        else:\n",
    "            accuracy_l[j] = 1.0\n",
    "\n",
    "        if 2 * tp + fp + fn:\n",
    "            fmeasure_l[j] = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "        else:\n",
    "            fmeasure_l[j] = 1.0\n",
    "\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        f_beta += fbeta_l[i]*C_l[i]\n",
    "        g_beta += gbeta_l[i]*C_l[i]\n",
    "        f_measure += fmeasure_l[i]*C_l[i]\n",
    "        accuracy += accuracy_l[i]*C_l[i]\n",
    "\n",
    "\n",
    "    f_beta = float(f_beta)/float(num_classes)\n",
    "    g_beta = float(g_beta)/float(num_classes)\n",
    "    f_measure = float(f_measure)/float(num_classes)\n",
    "    accuracy = float(accuracy)/float(num_classes)\n",
    "\n",
    "\n",
    "    return accuracy,f_measure,f_beta,g_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:49:53.722197Z",
     "start_time": "2020-04-29T03:47:03.776791Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = submitted_model.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:31:26.080144Z",
     "start_time": "2020-04-29T03:31:25.977600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2579, 9)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:31:50.145392Z",
     "start_time": "2020-04-29T03:31:50.042583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2579, 3000, 12)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:34:58.191079Z",
     "start_time": "2020-04-29T03:34:58.098519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1300, 9), (1300, 3000, 12))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hehe_y = test_y[:1300]\n",
    "hehe_x = test_x[:1300]\n",
    "\n",
    "hehe_y.shape, hehe_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:42:39.909552Z",
     "start_time": "2020-04-29T03:42:14.170097Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_s = submitted_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:43:19.027037Z",
     "start_time": "2020-04-29T03:42:51.393151Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_l = latest_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:43:30.627019Z",
     "start_time": "2020-04-29T03:43:30.572341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2579, 9), (2579, 9))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_s.shape, y_pred_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:57:48.912994Z",
     "start_time": "2020-04-29T03:57:48.754434Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, os, os.path, sys\n",
    "\n",
    "\n",
    "def evaluate_12ECG_score(label_directory, output_directory):\n",
    "\n",
    "    # Set parameters.\n",
    "    label_header       = '12ECGLabel'\n",
    "    output_label_header  = 'OutputLabel'\n",
    "    output_probability_header = 'OutputProbability'\n",
    "\n",
    "    beta = 2\n",
    "    labels=[]\n",
    "    output=[]\n",
    "    output_probabilities=[]\n",
    "\n",
    "    # Find label and output files.\n",
    "    label_files = []\n",
    "    for f in os.listdir(label_directory):\n",
    "        g = os.path.join(label_directory, f)\n",
    "        if os.path.isfile(g) and not f.lower().startswith('.') and f.lower().endswith('hea'):\n",
    "            label_files.append(g)\n",
    "    label_files = sorted(label_files)\n",
    "\n",
    "    output_files = []\n",
    "    for f in os.listdir(output_directory):\n",
    "        g = os.path.join(output_directory, f)\n",
    "        if os.path.isfile(g) and not f.lower().startswith('.') and f.lower().endswith('csv'):\n",
    "            output_files.append(g)\n",
    "    output_files = sorted(output_files)\n",
    "\n",
    "    if len(label_files) != len(output_files):\n",
    "        raise Exception('Numbers of label and output files must be the same.')\n",
    "\n",
    "    classes = get_classes(label_files)\n",
    "\n",
    "\n",
    "    # Load labels and outputs.\n",
    "    num_files = len(label_files)\n",
    "\n",
    "    for k in range(num_files):\n",
    "\n",
    "        recording_label,classes_label,single_recording_labels=get_true_labels(label_files[k],classes)\n",
    "        \n",
    "        with open(output_files[k],'r') as f:\n",
    "            tmp_data = f.readlines()\n",
    "        recording_output = tmp_data[0]\n",
    "        classes_output = tmp_data[1].split(',')\n",
    "        single_recording_output = np.array(tmp_data[2].split(','),np.int)\n",
    "        single_probabilities_output = np.array(tmp_data[3].split(','),np.float64)\n",
    "\n",
    "       # Check labels and output for errors.\n",
    "\n",
    "        if not (len(classes_label) == len(classes_output)):\n",
    "            raise Exception('Numbers of classes for a file must be the same.')\n",
    "        \n",
    "        if not (len(single_recording_labels) == len(single_recording_output) == len(single_probabilities_output)):\n",
    "            raise Exception('Numbers of labels and output for a file must be the same.')\n",
    "\n",
    "        labels.append(single_recording_labels)\n",
    "        output.append(single_recording_output)\n",
    "        output_probabilities.append(single_probabilities_output)\n",
    "\n",
    "    labels=np.array(labels)\n",
    "    output=np.array(output)\n",
    "    output_probabilities=np.array(output_probabilities)\n",
    "\n",
    "    num_classes = len(classes_label)\n",
    "\n",
    "    # Compute F_beta measure and the generalization of the Jaccard index\n",
    "    accuracy,f_measure,Fbeta_measure,Gbeta_measure = compute_beta_score(labels, output, beta, num_classes)\n",
    "\n",
    "    # compute AUROC and AUPRC\n",
    "    auroc,auprc = compute_auc(labels, output_probabilities,num_classes)\n",
    "\n",
    "    return auroc,auprc,accuracy,f_measure,Fbeta_measure,Gbeta_measure\n",
    "\n",
    "# Find unique number of classes\n",
    "def get_classes(files):\n",
    "\n",
    "    classes=set()\n",
    "    for input_file in files:\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    for c in tmp:\n",
    "                        classes.add(c.strip())\n",
    "\n",
    "    return sorted(classes)\n",
    "\n",
    "\n",
    "\n",
    "# Find unique true labels\n",
    "def get_true_labels(input_file,classes):\n",
    "\n",
    "    classes_label = classes\n",
    "    single_recording_labels=np.zeros(len(classes),dtype=int)\n",
    "\n",
    "\n",
    "    with open(input_file,'r') as f:\n",
    "        first_line = f.readline()\n",
    "        recording_label=first_line.split(' ')[0]\n",
    "        print(recording_label)\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                for c in tmp:\n",
    "                    idx = classes.index(c.strip())\n",
    "                    single_recording_labels[idx]=1\n",
    "\n",
    "    return recording_label,classes_label,single_recording_labels\n",
    "\n",
    "def compute_auc(labels, probabilities, num_classes, check_errors=True):\n",
    "\n",
    "\n",
    "    # Check inputs for errors.\n",
    "    if check_errors:\n",
    "        if len(labels) != len(probabilities):\n",
    "            raise Exception('Numbers of outputs and labels must be the same.')\n",
    "\n",
    "    find_NaNs = np.isnan(probabilities);\n",
    "    probabilities[find_NaNs] = 0;\n",
    "\n",
    "    auroc_l = np.zeros(num_classes)\n",
    "    auprc_l = np.zeros(num_classes)\n",
    "\n",
    "    auroc = 0\n",
    "    auprc = 0\n",
    "\n",
    "    # Weight function - this will change\n",
    "    C_l=np.ones(num_classes);\n",
    "\n",
    "    # Populate contingency table.\n",
    "    num_recordings = len(labels)\n",
    "\n",
    "    for k in range(num_classes):\n",
    "    \n",
    "\n",
    "            # Find probabilities thresholds.\n",
    "        thresholds = np.unique(probabilities[:,k])[::-1]\n",
    "        if thresholds[0] != 1:\n",
    "            thresholds = np.insert(thresholds, 0, 1)\n",
    "        if thresholds[-1] == 0:\n",
    "            thresholds = thresholds[:-1]\n",
    "\n",
    "        m = len(thresholds)\n",
    "    \n",
    "\n",
    "        # Populate contingency table across probabilities thresholds.\n",
    "        tp = np.zeros(m)\n",
    "        fp = np.zeros(m)\n",
    "        fn = np.zeros(m)\n",
    "        tn = np.zeros(m)\n",
    "\n",
    "        # Find indices that sort the predicted probabilities from largest to\n",
    "        # smallest.\n",
    "        idx = np.argsort(probabilities[:,k])[::-1]\n",
    "\n",
    "        i = 0\n",
    "        for j in range(m):\n",
    "            # Initialize contingency table for j-th probabilities threshold.\n",
    "            if j == 0:\n",
    "                tp[j] = 0\n",
    "                fp[j] = 0\n",
    "                fn[j] = np.sum(labels[:,k])\n",
    "                tn[j] = num_recordings - fn[j]\n",
    "            else:\n",
    "                tp[j] = tp[j - 1]\n",
    "                fp[j] = fp[j - 1]\n",
    "                fn[j] = fn[j - 1]\n",
    "                tn[j] = tn[j - 1]\n",
    "            # Update contingency table for i-th largest predicted probability.\n",
    "            while i < num_recordings and probabilities[idx[i],k] >= thresholds[j]:\n",
    "                if labels[idx[i],k]:\n",
    "                    tp[j] += 1\n",
    "                    fn[j] -= 1\n",
    "                else:\n",
    "                    fp[j] += 1\n",
    "                    tn[j] -= 1\n",
    "                i += 1\n",
    "\n",
    "        # Summarize contingency table.\n",
    "        tpr = np.zeros(m)\n",
    "        tnr = np.zeros(m)\n",
    "        ppv = np.zeros(m)\n",
    "        npv = np.zeros(m)\n",
    "\n",
    "\n",
    "        for j in range(m):\n",
    "            if tp[j] + fn[j]:\n",
    "                tpr[j] = float(tp[j]) / float(tp[j] + fn[j])\n",
    "            else:\n",
    "                tpr[j] = 1\n",
    "            if fp[j] + tn[j]:\n",
    "                tnr[j] = float(tn[j]) / float(fp[j] + tn[j])\n",
    "            else:\n",
    "                tnr[j] = 1\n",
    "            if tp[j] + fp[j]:\n",
    "                ppv[j] = float(tp[j]) / float(tp[j] + fp[j])\n",
    "            else:\n",
    "                ppv[j] = 1\n",
    "            if fn[j] + tn[j]:\n",
    "                npv[j] = float(tn[j]) / float(fn[j] + tn[j])\n",
    "            else:\n",
    "                npv[j] = 1\n",
    "\n",
    "        # Compute AUROC as the area under a piecewise linear function with TPR /\n",
    "        # sensitivity (x-axis) and TNR / specificity (y-axis) and AUPRC as the area\n",
    "        # under a piecewise constant with TPR / recall (x-axis) and PPV / precision\n",
    "        # (y-axis).\n",
    "\n",
    "        for j in range(m-1):\n",
    "            auroc_l[k] += 0.5 * (tpr[j + 1] - tpr[j]) * (tnr[j + 1] + tnr[j])\n",
    "            auprc_l[k] += (tpr[j + 1] - tpr[j]) * ppv[j + 1]\n",
    "\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        auroc += auroc_l[i]*C_l[i]\n",
    "        auprc += auprc_l[i]*C_l[i]\n",
    "\n",
    "    auroc = float(auroc)/float(num_classes)\n",
    "    auprc = float(auprc)/float(num_classes)\n",
    "\n",
    "    \n",
    "    return auroc, auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T03:58:01.053420Z",
     "start_time": "2020-04-29T03:58:00.294453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A6000\n",
      "A6001\n",
      "A6002\n",
      "A6003\n",
      "A6004\n",
      "A6005\n",
      "A6006\n",
      "A6007\n",
      "A6008\n",
      "A6009\n",
      "A6010\n",
      "A6011\n",
      "A6012\n",
      "A6013\n",
      "A6014\n",
      "A6015\n",
      "A6016\n",
      "A6017\n",
      "A6018\n",
      "A6019\n",
      "A6020\n",
      "A6021\n",
      "A6022\n",
      "A6023\n",
      "A6024\n",
      "A6025\n",
      "A6026\n",
      "A6027\n",
      "A6028\n",
      "A6029\n",
      "A6030\n",
      "A6031\n",
      "A6032\n",
      "A6033\n",
      "A6034\n",
      "A6035\n",
      "A6036\n",
      "A6037\n",
      "A6038\n",
      "A6039\n",
      "A6040\n",
      "A6041\n",
      "A6042\n",
      "A6043\n",
      "A6044\n",
      "A6045\n",
      "A6046\n",
      "A6047\n",
      "A6048\n",
      "A6049\n",
      "A6050\n",
      "A6051\n",
      "A6052\n",
      "A6053\n",
      "A6054\n",
      "A6055\n",
      "A6056\n",
      "A6057\n",
      "A6058\n",
      "A6059\n",
      "A6060\n",
      "A6061\n",
      "A6062\n",
      "A6063\n",
      "A6064\n",
      "A6065\n",
      "A6066\n",
      "A6067\n",
      "A6068\n",
      "A6069\n",
      "A6070\n",
      "A6071\n",
      "A6072\n",
      "A6073\n",
      "A6074\n",
      "A6075\n",
      "A6076\n",
      "A6077\n",
      "A6078\n",
      "A6079\n",
      "A6080\n",
      "A6081\n",
      "A6082\n",
      "A6083\n",
      "A6084\n",
      "A6085\n",
      "A6086\n",
      "A6087\n",
      "A6088\n",
      "A6089\n",
      "A6090\n",
      "A6091\n",
      "A6092\n",
      "A6093\n",
      "A6094\n",
      "A6095\n",
      "A6096\n",
      "A6097\n",
      "A6098\n",
      "A6099\n",
      "A6100\n",
      "A6101\n",
      "A6102\n",
      "A6103\n",
      "A6104\n",
      "A6105\n",
      "A6106\n",
      "A6107\n",
      "A6108\n",
      "A6109\n",
      "A6110\n",
      "A6111\n",
      "A6112\n",
      "A6113\n",
      "A6114\n",
      "A6115\n",
      "A6116\n",
      "A6117\n",
      "A6118\n",
      "A6119\n",
      "A6120\n",
      "A6121\n",
      "A6122\n",
      "A6123\n",
      "A6124\n",
      "A6125\n",
      "A6126\n",
      "A6127\n",
      "A6128\n",
      "A6129\n",
      "A6130\n",
      "A6131\n",
      "A6132\n",
      "A6133\n",
      "A6134\n",
      "A6135\n",
      "A6136\n",
      "A6137\n",
      "A6138\n",
      "A6139\n",
      "A6140\n",
      "A6141\n",
      "A6142\n",
      "A6143\n",
      "A6144\n",
      "A6145\n",
      "A6146\n",
      "A6147\n",
      "A6148\n",
      "A6149\n",
      "A6150\n",
      "A6151\n",
      "A6152\n",
      "A6153\n",
      "A6154\n",
      "A6155\n",
      "A6156\n",
      "A6157\n",
      "A6158\n",
      "A6159\n",
      "A6160\n",
      "A6161\n",
      "A6162\n",
      "A6163\n",
      "A6164\n",
      "A6165\n",
      "A6166\n",
      "A6167\n",
      "A6168\n",
      "A6169\n",
      "A6170\n",
      "A6171\n",
      "A6172\n",
      "A6173\n",
      "A6174\n",
      "A6175\n",
      "A6176\n",
      "A6177\n",
      "A6178\n",
      "A6179\n",
      "A6180\n",
      "A6181\n",
      "A6182\n",
      "A6183\n",
      "A6184\n",
      "A6185\n",
      "A6186\n",
      "A6187\n",
      "A6188\n",
      "A6189\n",
      "A6190\n",
      "A6191\n",
      "A6192\n",
      "A6193\n",
      "A6194\n",
      "A6195\n",
      "A6196\n",
      "A6197\n",
      "A6198\n",
      "A6199\n",
      "A6200\n",
      "A6201\n",
      "A6202\n",
      "A6203\n",
      "A6204\n",
      "A6205\n",
      "A6206\n",
      "A6207\n",
      "A6208\n",
      "A6209\n",
      "A6210\n",
      "A6211\n",
      "A6212\n",
      "A6213\n",
      "A6214\n",
      "A6215\n",
      "A6216\n",
      "A6217\n",
      "A6218\n",
      "A6219\n",
      "A6220\n",
      "A6221\n",
      "A6222\n",
      "A6223\n",
      "A6224\n",
      "A6225\n",
      "A6226\n",
      "A6227\n",
      "A6228\n",
      "A6229\n",
      "A6230\n",
      "A6231\n",
      "A6232\n",
      "A6233\n",
      "A6234\n",
      "A6235\n",
      "A6236\n",
      "A6237\n",
      "A6238\n",
      "A6239\n",
      "A6240\n",
      "A6241\n",
      "A6242\n",
      "A6243\n",
      "A6244\n",
      "A6245\n",
      "A6246\n",
      "A6247\n",
      "A6248\n",
      "A6249\n",
      "A6250\n",
      "A6251\n",
      "A6252\n",
      "A6253\n",
      "A6254\n",
      "A6255\n",
      "A6256\n",
      "A6257\n",
      "A6258\n",
      "A6259\n",
      "A6260\n",
      "A6261\n",
      "A6262\n",
      "A6263\n",
      "A6264\n",
      "A6265\n",
      "A6266\n",
      "A6267\n",
      "A6268\n",
      "A6269\n",
      "A6270\n",
      "A6271\n",
      "A6272\n",
      "A6273\n",
      "A6274\n",
      "A6275\n",
      "A6276\n",
      "A6277\n",
      "A6278\n",
      "A6279\n",
      "A6280\n",
      "A6281\n",
      "A6282\n",
      "A6283\n",
      "A6284\n",
      "A6285\n",
      "A6286\n",
      "A6287\n",
      "A6288\n",
      "A6289\n",
      "A6290\n",
      "A6291\n",
      "A6292\n",
      "A6293\n",
      "A6294\n",
      "A6295\n",
      "A6296\n",
      "A6297\n",
      "A6298\n",
      "A6299\n",
      "A6300\n",
      "A6301\n",
      "A6302\n",
      "A6303\n",
      "A6304\n",
      "A6305\n",
      "A6306\n",
      "A6307\n",
      "A6308\n",
      "A6309\n",
      "A6310\n",
      "A6311\n",
      "A6312\n",
      "A6313\n",
      "A6314\n",
      "A6315\n",
      "A6316\n",
      "A6317\n",
      "A6318\n",
      "A6319\n",
      "A6320\n",
      "A6321\n",
      "A6322\n",
      "A6323\n",
      "A6324\n",
      "A6325\n",
      "A6326\n",
      "A6327\n",
      "A6328\n",
      "A6329\n",
      "A6330\n",
      "A6331\n",
      "A6332\n",
      "A6333\n",
      "A6334\n",
      "A6335\n",
      "A6336\n",
      "A6337\n",
      "A6338\n",
      "A6339\n",
      "A6340\n",
      "A6341\n",
      "A6342\n",
      "A6343\n",
      "A6344\n",
      "A6345\n",
      "A6346\n",
      "A6347\n",
      "A6348\n",
      "A6349\n",
      "A6350\n",
      "A6351\n",
      "A6352\n",
      "A6353\n",
      "A6354\n",
      "A6355\n",
      "A6356\n",
      "A6357\n",
      "A6358\n",
      "A6359\n",
      "A6360\n",
      "A6361\n",
      "A6362\n",
      "A6363\n",
      "A6364\n",
      "A6365\n",
      "A6366\n",
      "A6367\n",
      "A6368\n",
      "A6369\n",
      "A6370\n",
      "A6371\n",
      "A6372\n",
      "A6373\n",
      "A6374\n",
      "A6375\n",
      "A6376\n",
      "A6377\n",
      "A6378\n",
      "A6379\n",
      "A6380\n",
      "A6381\n",
      "A6382\n",
      "A6383\n",
      "A6384\n",
      "A6385\n",
      "A6386\n",
      "A6387\n",
      "A6388\n",
      "A6389\n",
      "A6390\n",
      "A6391\n",
      "A6392\n",
      "A6393\n",
      "A6394\n",
      "A6395\n",
      "A6396\n",
      "A6397\n",
      "A6398\n",
      "A6399\n",
      "A6400\n",
      "A6401\n",
      "A6402\n",
      "A6403\n",
      "A6404\n",
      "A6405\n",
      "A6406\n",
      "A6407\n",
      "A6408\n",
      "A6409\n",
      "A6410\n",
      "A6411\n",
      "A6412\n",
      "A6413\n",
      "A6414\n",
      "A6415\n",
      "A6416\n",
      "A6417\n",
      "A6418\n",
      "A6419\n",
      "A6420\n",
      "A6421\n",
      "A6422\n",
      "A6423\n",
      "A6424\n",
      "A6425\n",
      "A6426\n",
      "A6427\n",
      "A6428\n",
      "A6429\n",
      "A6430\n",
      "A6431\n",
      "A6432\n",
      "A6433\n",
      "A6434\n",
      "A6435\n",
      "A6436\n",
      "A6437\n",
      "A6438\n",
      "A6439\n",
      "A6440\n",
      "A6441\n",
      "A6442\n",
      "A6443\n",
      "A6444\n",
      "A6445\n",
      "A6446\n",
      "A6447\n",
      "A6448\n",
      "A6449\n",
      "A6450\n",
      "A6451\n",
      "A6452\n",
      "A6453\n",
      "A6454\n",
      "A6455\n",
      "A6456\n",
      "A6457\n",
      "A6458\n",
      "A6459\n",
      "A6460\n",
      "A6461\n",
      "A6462\n",
      "A6463\n",
      "A6464\n",
      "A6465\n",
      "A6466\n",
      "A6467\n",
      "A6468\n",
      "A6469\n",
      "A6470\n",
      "A6471\n",
      "A6472\n",
      "A6473\n",
      "A6474\n",
      "A6475\n",
      "A6476\n",
      "A6477\n",
      "A6478\n",
      "A6479\n",
      "A6480\n",
      "A6481\n",
      "A6482\n",
      "A6483\n",
      "A6484\n",
      "A6485\n",
      "A6486\n",
      "A6487\n",
      "A6488\n",
      "A6489\n",
      "A6490\n",
      "A6491\n",
      "A6492\n",
      "A6493\n",
      "A6494\n",
      "A6495\n",
      "A6496\n",
      "A6497\n",
      "A6498\n",
      "A6499\n",
      "A6500\n",
      "A6501\n",
      "A6502\n",
      "A6503\n",
      "A6504\n",
      "A6505\n",
      "A6506\n",
      "A6507\n",
      "A6508\n",
      "A6509\n",
      "A6510\n",
      "A6511\n",
      "A6512\n",
      "A6513\n",
      "A6514\n",
      "A6515\n",
      "A6516\n",
      "A6517\n",
      "A6518\n",
      "A6519\n",
      "A6520\n",
      "A6521\n",
      "A6522\n",
      "A6523\n",
      "A6524\n",
      "A6525\n",
      "A6526\n",
      "A6527\n",
      "A6528\n",
      "A6529\n",
      "A6530\n",
      "A6531\n",
      "A6532\n",
      "A6533\n",
      "A6534\n",
      "A6535\n",
      "A6536\n",
      "A6537\n",
      "A6538\n",
      "A6539\n",
      "A6540\n",
      "A6541\n",
      "A6542\n",
      "A6543\n",
      "A6544\n",
      "A6545\n",
      "A6546\n",
      "A6547\n",
      "A6548\n",
      "A6549\n",
      "A6550\n",
      "A6551\n",
      "A6552\n",
      "A6553\n",
      "A6554\n",
      "A6555\n",
      "A6556\n",
      "A6557\n",
      "A6558\n",
      "A6559\n",
      "A6560\n",
      "A6561\n",
      "A6562\n",
      "A6563\n",
      "A6564\n",
      "A6565\n",
      "A6566\n",
      "A6567\n",
      "A6568\n",
      "A6569\n",
      "A6570\n",
      "A6571\n",
      "A6572\n",
      "A6573\n",
      "A6574\n",
      "A6575\n",
      "A6576\n",
      "A6577\n",
      "A6578\n",
      "A6579\n",
      "A6580\n",
      "A6581\n",
      "A6582\n",
      "A6583\n",
      "A6584\n",
      "A6585\n",
      "A6586\n",
      "A6587\n",
      "A6588\n",
      "A6589\n",
      "A6590\n",
      "A6591\n",
      "A6592\n",
      "A6593\n",
      "A6594\n",
      "A6595\n",
      "A6596\n",
      "A6597\n",
      "A6598\n",
      "A6599\n",
      "A6600\n",
      "A6601\n",
      "A6602\n",
      "A6603\n",
      "A6604\n",
      "A6605\n",
      "A6606\n",
      "A6607\n",
      "A6608\n",
      "A6609\n",
      "A6610\n",
      "A6611\n",
      "A6612\n",
      "A6613\n",
      "A6614\n",
      "A6615\n",
      "A6616\n",
      "A6617\n",
      "A6618\n",
      "A6619\n",
      "A6620\n",
      "A6621\n",
      "A6622\n",
      "A6623\n",
      "A6624\n",
      "A6625\n",
      "A6626\n",
      "A6627\n",
      "A6628\n",
      "A6629\n",
      "A6630\n",
      "A6631\n",
      "A6632\n",
      "A6633\n",
      "A6634\n",
      "A6635\n",
      "A6636\n",
      "A6637\n",
      "A6638\n",
      "A6639\n",
      "A6640\n",
      "A6641\n",
      "A6642\n",
      "A6643\n",
      "A6644\n",
      "A6645\n",
      "A6646\n",
      "A6647\n",
      "A6648\n",
      "A6649\n",
      "A6650\n",
      "A6651\n",
      "A6652\n",
      "A6653\n",
      "A6654\n",
      "A6655\n",
      "A6656\n",
      "A6657\n",
      "A6658\n",
      "A6659\n",
      "A6660\n",
      "A6661\n",
      "A6662\n",
      "A6663\n",
      "A6664\n",
      "A6665\n",
      "A6666\n",
      "A6667\n",
      "A6668\n",
      "A6669\n",
      "A6670\n",
      "A6671\n",
      "A6672\n",
      "A6673\n",
      "A6674\n",
      "A6675\n",
      "A6676\n",
      "A6677\n",
      "A6678\n",
      "A6679\n",
      "A6680\n",
      "A6681\n",
      "A6682\n",
      "A6683\n",
      "A6684\n",
      "A6685\n",
      "A6686\n",
      "A6687\n",
      "A6688\n",
      "A6689\n",
      "A6690\n",
      "A6691\n",
      "A6692\n",
      "A6693\n",
      "A6694\n",
      "A6695\n",
      "A6696\n",
      "A6697\n",
      "A6698\n",
      "A6699\n",
      "A6700\n",
      "A6701\n",
      "A6702\n",
      "A6703\n",
      "A6704\n",
      "A6705\n",
      "A6706\n",
      "A6707\n",
      "A6708\n",
      "A6709\n",
      "A6710\n",
      "A6711\n",
      "A6712\n",
      "A6713\n",
      "A6714\n",
      "A6715\n",
      "A6716\n",
      "A6717\n",
      "A6718\n",
      "A6719\n",
      "A6720\n",
      "A6721\n",
      "A6722\n",
      "A6723\n",
      "A6724\n",
      "A6725\n",
      "A6726\n",
      "A6727\n",
      "A6728\n",
      "A6729\n",
      "A6730\n",
      "A6731\n",
      "A6732\n",
      "A6733\n",
      "A6734\n",
      "A6735\n",
      "A6736\n",
      "A6737\n",
      "A6738\n",
      "A6739\n",
      "A6740\n",
      "A6741\n",
      "A6742\n",
      "A6743\n",
      "A6744\n",
      "A6745\n",
      "A6746\n",
      "A6747\n",
      "A6748\n",
      "A6749\n",
      "A6750\n",
      "A6751\n",
      "A6752\n",
      "A6753\n",
      "A6754\n",
      "A6755\n",
      "A6756\n",
      "A6757\n",
      "A6758\n",
      "A6759\n",
      "A6760\n",
      "A6761\n",
      "A6762\n",
      "A6763\n",
      "A6764\n",
      "A6765\n",
      "A6766\n",
      "A6767\n",
      "A6768\n",
      "A6769\n",
      "A6770\n",
      "A6771\n",
      "A6772\n",
      "A6773\n",
      "A6774\n",
      "A6775\n",
      "A6776\n",
      "A6777\n",
      "A6778\n",
      "A6779\n",
      "A6780\n",
      "A6781\n",
      "A6782\n",
      "A6783\n",
      "A6784\n",
      "A6785\n",
      "A6786\n",
      "A6787\n",
      "A6788\n",
      "A6789\n",
      "A6790\n",
      "A6791\n",
      "A6792\n",
      "A6793\n",
      "A6794\n",
      "A6795\n",
      "A6796\n",
      "A6797\n",
      "A6798\n",
      "A6799\n",
      "A6800\n",
      "A6801\n",
      "A6802\n",
      "A6803\n",
      "A6804\n",
      "A6805\n",
      "A6806\n",
      "A6807\n",
      "A6808\n",
      "A6809\n",
      "A6810\n",
      "A6811\n",
      "A6812\n",
      "A6813\n",
      "A6814\n",
      "A6815\n",
      "A6816\n",
      "A6817\n",
      "A6818\n",
      "A6819\n",
      "A6820\n",
      "A6821\n",
      "A6822\n",
      "A6823\n",
      "A6824\n",
      "A6825\n",
      "A6826\n",
      "A6827\n",
      "A6828\n",
      "A6829\n",
      "A6830\n",
      "A6831\n",
      "A6832\n",
      "A6833\n",
      "A6834\n",
      "A6835\n",
      "A6836\n",
      "A6837\n",
      "A6838\n",
      "A6839\n",
      "A6840\n",
      "A6841\n",
      "A6842\n",
      "A6843\n",
      "A6844\n",
      "A6845\n",
      "A6846\n",
      "A6847\n",
      "A6848\n",
      "A6849\n",
      "A6850\n",
      "A6851\n",
      "A6852\n",
      "A6853\n",
      "A6854\n",
      "A6855\n",
      "A6856\n",
      "A6857\n",
      "A6858\n",
      "A6859\n",
      "A6860\n",
      "A6861\n",
      "A6862\n",
      "A6863\n",
      "A6864\n",
      "A6865\n",
      "A6866\n",
      "A6867\n",
      "A6868\n",
      "A6869\n",
      "A6870\n",
      "A6871\n",
      "A6872\n",
      "A6873\n",
      "A6874\n",
      "A6875\n",
      "A6876\n",
      "A6877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8692422110291568,\n",
       " 0.6546668843423026,\n",
       " 0.9297208538587848,\n",
       " 0.5935410020499682,\n",
       " 0.5764341435248892,\n",
       " 0.37287823676306764)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_12ECG_score(\"./tmp_data/input_labels/\", \"./tmp_data/output_labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
